{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import binascii\n",
    "# import os\n",
    "\n",
    "# PATH = 'dataset/'\n",
    "# types = os.listdir(PATH)\n",
    "\n",
    "# for fType in types:\n",
    "#     files = os.listdir(PATH + fType + '/')\n",
    "#     for file in files:\n",
    "#         with open(PATH + fType + '/' + file, 'rb') as f:\n",
    "#             content = f.read()\n",
    "#             file_array = binascii.hexlify(content)\n",
    "#             print(file, file_array[:10])\n",
    "#     print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the training dataset\n",
    "import binascii\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm_notebook\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "PATH = 'dataset/'\n",
    "SAVE_PATH = 'D:/Freelance big/Mohammed A/'\n",
    "types = os.listdir(PATH)\n",
    "\n",
    "CHARS = np.array(list(map(chr, list(np.arange(97, 122)))) + list(np.arange(0, 10)))\n",
    "NUM_CHARS = len(CHARS)\n",
    "LINE_LENGTH = 20\n",
    "ohe.fit(CHARS.reshape(-1, 1))\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "N_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category mapping: {0: 'bmp', 1: 'flv', 2: 'jpg', 3: 'mp3', 4: 'mp4', 5: 'pdf', 6: 'png', 7: 'wav'}\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "def to_tensor(line, ohe, maxchars):\n",
    "    '''\n",
    "    One Hot Encodes the line of symbols and then transforms to torch tensor, to pass into the model\n",
    "    :param line: Line of char symbols\n",
    "    :param ohe: OneHotEncoder instance\n",
    "    :param maxchars: Number of chars to take from the both sides of line\n",
    "    :return: Torch Tensor of one hot encoded line\n",
    "    '''\n",
    "    \n",
    "    return ohe.transform(line.reshape(-1, 1)).todense()\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Custom Dataset object for the CDiscount competition\n",
    "        Parameters:\n",
    "            root_dir - directory including category folders with images\n",
    "\n",
    "        Example:\n",
    "        images/\n",
    "            1000001859/\n",
    "                26_0.jpg\n",
    "                26_1.jpg\n",
    "                ...\n",
    "            1000004141/\n",
    "                ...\n",
    "            ...\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.categories = sorted(os.listdir(root_dir))\n",
    "        self.cat2idx = dict(zip(self.categories, range(len(self.categories))))\n",
    "        self.idx2cat = dict(zip(self.cat2idx.values(), self.cat2idx.keys()))\n",
    "        self.files = []\n",
    "        cat_mapping = {}\n",
    "        for (dirpath, dirnames, filenames) in os.walk(self.root_dir):\n",
    "            for f in filenames:\n",
    "                if 0 == 0:\n",
    "                    o = {}\n",
    "                    o['f_path'] = dirpath + '/' + f\n",
    "                    o['category'] = self.cat2idx[dirpath[dirpath.find('/')+1:]]\n",
    "                    cat_mapping[o['category']] = dirpath.split('/')[-1]\n",
    "                    self.files.append(o)\n",
    "        print(f'category mapping: {cat_mapping}')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        f_path = self.files[idx]['f_path']\n",
    "        category = self.files[idx]['category']\n",
    "        \n",
    "        with open(f_path, 'rb') as f:\n",
    "            content = binascii.hexlify(f.read())\n",
    "            content = list(content[:LINE_LENGTH].decode(\"utf-8\")) + list(content[-LINE_LENGTH:].decode(\"utf-8\"))\n",
    "            file_array = np.array(content)\n",
    "            nToReplace = np.random.randint(0, 10+1)\n",
    "            \n",
    "            indexes = np.random.choice(np.arange(LINE_LENGTH), nToReplace, replace = False)\n",
    "            file_array[indexes] = np.random.choice(CHARS, nToReplace)\n",
    "            \n",
    "            indexes = np.random.choice(np.arange(len(file_array) - LINE_LENGTH, len(file_array)), nToReplace, replace = False)\n",
    "            file_array[indexes] = np.random.choice(CHARS, nToReplace)\n",
    "            data = np.array(to_tensor(file_array, ohe, LINE_LENGTH)).reshape(1, 2*LINE_LENGTH, NUM_CHARS)\n",
    "        \n",
    "        return {'data': data, 'category': category}\n",
    "\n",
    "\n",
    "# create instance of data class and pytorch dataloader\n",
    "dataSet = Dataset(PATH)\n",
    "dataloader = torch.utils.data.DataLoader(dataSet, batch_size=BATCH_SIZE, shuffle=True)\n",
    "MAPPING = {0: 'bmp', 1: 'flv', 2: 'jpg', 3: 'mp3', 4: 'mp4', 5: 'pdf', 6: 'png', 7: 'wav'}\n",
    "N_CLASSES = len(MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(3, 8, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (conv3): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv4): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (dropout): Dropout(p=0.3)\n",
       "  (fc1): Linear(in_features=640, out_features=128, bias=True)\n",
       "  (bnorm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (bnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=64, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn  as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    '''\n",
    "    Represents the structure of pytorch CNN model\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, N_CLASSES):\n",
    "        '''\n",
    "        Describes all layers, contained in the model\n",
    "        :param N_CLASSES: Number of output classes of the model\n",
    "        '''\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 3, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(3, 8, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(8, 16, 5)\n",
    "        self.conv4 = nn.Conv2d(16,32, 5)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc1 = nn.Linear(32 * 5 * 4, 128)\n",
    "        self.bnorm1 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bnorm2 = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.fc3 = nn.Linear(64, N_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Displays the connections between model layers for the forward pass\n",
    "        :param x: input torch tensor\n",
    "        :return: model prediction\n",
    "        '''\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = x.view(-1, 32 * 5 * 4)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bnorm1(self.fc1(x)))\n",
    "        x = F.relu(self.bnorm2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = Net(N_CLASSES).double()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training!\n",
      "[1,    14] loss: 0.125\n",
      "[2,    14] loss: 0.111\n",
      "[3,    14] loss: 0.079\n",
      "[4,    14] loss: 0.062\n",
      "[5,    14] loss: 0.055\n",
      "[6,    14] loss: 0.051\n",
      "[7,    14] loss: 0.045\n",
      "[8,    14] loss: 0.036\n",
      "[9,    14] loss: 0.035\n",
      "[10,    14] loss: 0.034\n",
      "[11,    14] loss: 0.026\n",
      "[12,    14] loss: 0.026\n",
      "[13,    14] loss: 0.024\n",
      "[14,    14] loss: 0.021\n",
      "[15,    14] loss: 0.023\n",
      "[16,    14] loss: 0.024\n",
      "[17,    14] loss: 0.018\n",
      "[18,    14] loss: 0.016\n",
      "[19,    14] loss: 0.019\n",
      "[20,    14] loss: 0.018\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "### Training loop for the model\n",
    "criterion = nn.CrossEntropyLoss() # loss function\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=1e-3) # optimizer for the loss function\n",
    "\n",
    "print('Started Training!')\n",
    "net.train()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    examples = 0\n",
    "    # for batch of the data perform forward pass and \n",
    "    # update the gradients \n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data['data'], data['category']\n",
    "        \n",
    "        # Wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        #print(outputs.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.data\n",
    "        examples += BATCH_SIZE\n",
    "    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / examples))\n",
    "\n",
    "print('Finished Training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n",
      "bmp\n"
     ]
    }
   ],
   "source": [
    "# Example prediction\n",
    "net.eval()\n",
    "path = 'dataset/bmp/'\n",
    "for file in os.listdir(path):\n",
    "    with open(path + file, 'rb') as f:\n",
    "        content = binascii.hexlify(f.read())\n",
    "        content = list(content[:LINE_LENGTH].decode(\"utf-8\")) + list(content[-LINE_LENGTH:].decode(\"utf-8\"))\n",
    "        file_array = np.array(content)\n",
    "        #file_array = binascii.hexlify(content)\n",
    "        nToReplace = np.random.randint(0, 5+1)\n",
    "\n",
    "        indexes = np.random.choice(np.arange(LINE_LENGTH), nToReplace, replace = False)\n",
    "        file_array[indexes] = np.random.choice(CHARS, nToReplace)\n",
    "\n",
    "        indexes = np.random.choice(np.arange(len(file_array) - LINE_LENGTH, len(file_array)), nToReplace, replace = False)\n",
    "        file_array[indexes] = np.random.choice(CHARS, nToReplace)\n",
    "        inp = torch.from_numpy(to_tensor(file_array, ohe, LINE_LENGTH)).reshape(1, 1, 2*LINE_LENGTH, NUM_CHARS).double().to(device)\n",
    "\n",
    "        output = net(inp)\n",
    "        print(MAPPING[np.argmax(output.cpu().detach().numpy())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "png png\n",
      "jpg jpg\n",
      "pdf pdf\n",
      "bmp bmp\n",
      "png png\n",
      "jpg jpg\n",
      "png png\n",
      "wav wav\n",
      "png png\n"
     ]
    }
   ],
   "source": [
    "# Example prediction\n",
    "net.eval()\n",
    "path = 'TEST/'\n",
    "for file in os.listdir(path):\n",
    "    with open(path + file, 'rb') as f:\n",
    "        content = binascii.hexlify(f.read())\n",
    "        content = list(content[:LINE_LENGTH].decode(\"utf-8\")) + list(content[-LINE_LENGTH:].decode(\"utf-8\"))\n",
    "        file_array = np.array(content)\n",
    "        #file_array = binascii.hexlify(content)\n",
    "        nToReplace = np.random.randint(0, 5+1)\n",
    "\n",
    "        indexes = np.random.choice(np.arange(LINE_LENGTH), nToReplace, replace = False)\n",
    "        file_array[indexes] = np.random.choice(CHARS, nToReplace)\n",
    "\n",
    "        indexes = np.random.choice(np.arange(len(file_array) - LINE_LENGTH, len(file_array)), nToReplace, replace = False)\n",
    "        file_array[indexes] = np.random.choice(CHARS, nToReplace)\n",
    "        inp = torch.from_numpy(to_tensor(file_array, ohe, LINE_LENGTH)).reshape(1, 1, 2*LINE_LENGTH, NUM_CHARS).double().to(device)\n",
    "\n",
    "        output = net(inp)\n",
    "        print(file.split('.')[-1], MAPPING[np.argmax(output.cpu().detach().numpy())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving torch model\n",
    "torch.save(net.state_dict(), SAVE_PATH + 'model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
